{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T18:09:56.465821Z",
     "start_time": "2024-11-22T18:09:55.244682Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_data_stats(file_path):\n",
    "    # Load the stats with weights_only=False\n",
    "    stats = torch.load(file_path, weights_only=False)\n",
    "\n",
    "    # Parse and print statistics\n",
    "    print(f\"Loading stats from: {file_path}\")\n",
    "\n",
    "    pose_mean = stats[\"pose_mean\"].reshape(-1)\n",
    "    pose_std = stats[\"pose_std\"].reshape(-1)\n",
    "    face_mean = stats[\"code_mean\"].reshape(-1)\n",
    "    face_std = stats[\"code_std\"].reshape(-1)\n",
    "    audio_mean = stats[\"audio_mean\"].reshape(-1)\n",
    "    audio_std = stats[\"audio_std_flat\"].reshape(-1)\n",
    "    print(stats.keys())\n",
    "    print(f\"Pose mean shape: {pose_mean.shape}\")\n",
    "    print(f\"Pose std shape: {pose_std.shape}\")\n",
    "    print(f\"Face mean shape: {face_mean.shape}\")\n",
    "    print(f\"Face std shape: {face_std.shape}\")\n",
    "    print(f\"Audio mean shape: {audio_mean}\")\n",
    "    print(f\"Audio std shape: {audio_std}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Load stats\n",
    "stats = parse_data_stats(\"./dataset/GQS883/data_stats.pth\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stats from: ./dataset/GQS883/data_stats.pth\n",
      "dict_keys(['code_std_flat', 'code_std', 'code_mean', 'pose_std_flat', 'pose_std', 'pose_mean', 'audio_std_flat', 'audio_std', 'audio_mean'])\n",
      "Pose mean shape: (104,)\n",
      "Pose std shape: (104,)\n",
      "Face mean shape: (256,)\n",
      "Face std shape: (256,)\n",
      "Audio mean shape: [-7.8997459e-08 -1.5775761e-07]\n",
      "Audio std shape: [0.01367152]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T18:43:06.278575Z",
     "start_time": "2024-11-22T18:42:54.375879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def create_multipart_request():\n",
    "    # Prepare the files\n",
    "    files = []\n",
    "    base_dir = './dataset/GQS883/'\n",
    "    audio_files = ['scene01_audio.wav']\n",
    "\n",
    "    for filename in audio_files:\n",
    "        filepath = os.path.join(base_dir, filename)\n",
    "        files.append(('file', (filename, open(filepath, 'rb'))))\n",
    "\n",
    "    # Prepare the request\n",
    "    response = requests.post(\n",
    "        \"https://api.hume.ai/v0/batch/jobs\",\n",
    "        headers={\n",
    "            \"X-Hume-Api-Key\": \"1sJm18G85hBifTpuITNw8OvubszP0rAdstFuf6EWfAP8I2a6\"\n",
    "        },\n",
    "        data={\n",
    "            'json': json.dumps({\n",
    "                \"models\": {\n",
    "                    \"burst\": {},\n",
    "                    \"prosody\": {},\n",
    "                    \"language\": {},\n",
    "                    \"ner\": {}\n",
    "                }\n",
    "            }),\n",
    "        },\n",
    "        files=files\n",
    "    )\n",
    "\n",
    "    return parse_job_response(response)\n",
    "\n",
    "def parse_job_response(response):\n",
    "   try:\n",
    "       return response.json().get('job_id')\n",
    "   except ValueError:\n",
    "       print(\"Error parsing JSON\")\n",
    "       return None\n",
    "# Execute the request\n",
    "response = create_multipart_request()\n",
    "\n",
    "# Print response details\n",
    "print(\"Status Code:\", response)"
   ],
   "id": "e09b0e189c5c77d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: c1abd7bf-37e3-41bc-9c71-236cc656fe75\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:28:02.490488Z",
     "start_time": "2024-11-22T21:28:01.543764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "# Get job predictions (GET /v0/batch/jobs/:id/predictions)\n",
    "response = requests.get(\n",
    "  \"https://api.hume.ai/v0/batch/jobs/aaa72c03-c345-467f-b076-296960463683/predictions\",\n",
    "  headers={\n",
    "    \"X-Hume-Api-Key\": \"1sJm18G85hBifTpuITNw8OvubszP0rAdstFuf6EWfAP8I2a6\"\n",
    "  },\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=2))"
   ],
   "id": "84c89adb79ac0691",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_to_json(data, filename='response.json'):\n",
    "   \"\"\"保存数据到JSON文件\"\"\"\n",
    "   with open(filename, 'w', encoding='utf-8') as f:\n",
    "       json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "   print(f\"Data saved to {filename}\")\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "# Get job predictions (GET /v0/batch/jobs/:id/predictions)\n",
    "response = requests.get(\n",
    "  \"https://api.hume.ai/v0/batch/jobs/aaa72c03-c345-467f-b076-296960463683/predictions\",\n",
    "  headers={\n",
    "    \"X-Hume-Api-Key\": \"1sJm18G85hBifTpuITNw8OvubszP0rAdstFuf6EWfAP8I2a6\"\n",
    "  },\n",
    ")\n",
    "\n",
    "# 保存响应数据\n",
    "save_to_json(response.json())"
   ],
   "id": "e10799666921311b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
